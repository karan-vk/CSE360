{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop('Outcome')\n",
    "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.8*len(df)), int(0.9*len(df))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.concat([test, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20052083333333334"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5\n",
    "# train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "# val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "# test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([keras.layers.Dense(8,activation=\"relu\"), keras.layers.Dense(1,activation=\"sigmoid\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(512, activation='relu', input_shape=(8,)))\n",
    "# model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(56, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(8, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "                           tf.keras.layers.Dense(128,activation='tanh',input_shape=(8,)),\n",
    "                           tf.keras.layers.Dropout(0.1),\n",
    "                           tf.keras.layers.Dense(108,activation='relu'),\n",
    "                           tf.keras.layers.Dropout(0.3), \n",
    "                           tf.keras.layers.Dense(56,activation='tanh'),\n",
    "                           tf.keras.layers.Dropout(0.125),\n",
    "                           tf.keras.layers.Dense(24,activation='exponential'),\n",
    "                           tf.keras.layers.Dropout(0.3),\n",
    "                           tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17647059 0.41919192 0.47540984 ... 0.57744108 0.11016225 0.06666667]\n",
      " [0.47058824 0.37373737 0.57377049 ... 0.59427609 0.2677199  0.3       ]\n",
      " [0.         0.84343434 0.         ... 0.54377104 0.32493595 0.15      ]\n",
      " ...\n",
      " [0.11764706 0.55050505 0.75409836 ... 0.71885522 0.32749787 0.55      ]\n",
      " [0.11764706 0.40909091 0.49180328 ... 0.46632997 0.09052092 0.06666667]\n",
      " [0.35294118 0.63131313 0.63934426 ... 0.46464646 0.20794193 0.46666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train.drop('Outcome', axis=1))\n",
    "scaled_test = scaler.transform(val.drop('Outcome', axis=1))\n",
    "print(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karan\\miniconda3\\envs\\cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 0.7117 - accuracy: 0.6042 - val_loss: 0.6688 - val_accuracy: 0.6169 - 694ms/epoch - 69ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 0.7279 - accuracy: 0.6042 - val_loss: 0.6460 - val_accuracy: 0.6169 - 58ms/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 0.6815 - accuracy: 0.6026 - val_loss: 0.6509 - val_accuracy: 0.6169 - 56ms/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 0.6547 - accuracy: 0.6368 - val_loss: 0.6335 - val_accuracy: 0.6169 - 54ms/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 0.6504 - accuracy: 0.6466 - val_loss: 0.6249 - val_accuracy: 0.6169 - 57ms/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 0.6434 - accuracy: 0.6401 - val_loss: 0.6216 - val_accuracy: 0.6169 - 52ms/epoch - 5ms/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 0.6320 - accuracy: 0.6661 - val_loss: 0.6175 - val_accuracy: 0.6169 - 46ms/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.6345 - accuracy: 0.6580 - val_loss: 0.6099 - val_accuracy: 0.6883 - 51ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.6219 - accuracy: 0.6694 - val_loss: 0.6329 - val_accuracy: 0.6169 - 59ms/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.6163 - accuracy: 0.6678 - val_loss: 0.6240 - val_accuracy: 0.6169 - 56ms/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.6313 - accuracy: 0.6450 - val_loss: 0.6169 - val_accuracy: 0.6169 - 49ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.6193 - accuracy: 0.6531 - val_loss: 0.5968 - val_accuracy: 0.6234 - 47ms/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.6122 - accuracy: 0.6515 - val_loss: 0.5896 - val_accuracy: 0.6234 - 43ms/epoch - 4ms/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.6114 - accuracy: 0.6629 - val_loss: 0.5769 - val_accuracy: 0.6818 - 41ms/epoch - 4ms/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6063 - accuracy: 0.6726 - val_loss: 0.6056 - val_accuracy: 0.6169 - 66ms/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.5805 - accuracy: 0.6954 - val_loss: 0.5702 - val_accuracy: 0.6623 - 52ms/epoch - 5ms/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.5876 - accuracy: 0.6954 - val_loss: 0.5658 - val_accuracy: 0.6688 - 46ms/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6014 - accuracy: 0.6759 - val_loss: 0.5481 - val_accuracy: 0.7208 - 39ms/epoch - 4ms/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.5649 - accuracy: 0.6954 - val_loss: 0.5494 - val_accuracy: 0.6818 - 43ms/epoch - 4ms/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.5731 - accuracy: 0.6710 - val_loss: 0.5304 - val_accuracy: 0.7078 - 42ms/epoch - 4ms/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.5556 - accuracy: 0.7117 - val_loss: 0.5383 - val_accuracy: 0.6883 - 47ms/epoch - 5ms/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.5771 - accuracy: 0.6938 - val_loss: 0.5179 - val_accuracy: 0.7208 - 42ms/epoch - 4ms/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.5492 - accuracy: 0.7085 - val_loss: 0.5271 - val_accuracy: 0.7078 - 44ms/epoch - 4ms/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.5339 - accuracy: 0.7215 - val_loss: 0.5259 - val_accuracy: 0.7727 - 41ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.5508 - accuracy: 0.7296 - val_loss: 0.5176 - val_accuracy: 0.7078 - 40ms/epoch - 4ms/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.5661 - accuracy: 0.7117 - val_loss: 0.4995 - val_accuracy: 0.7468 - 44ms/epoch - 4ms/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.5404 - accuracy: 0.7313 - val_loss: 0.4913 - val_accuracy: 0.7792 - 57ms/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.5369 - accuracy: 0.7345 - val_loss: 0.5258 - val_accuracy: 0.6883 - 59ms/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.5273 - accuracy: 0.7443 - val_loss: 0.4942 - val_accuracy: 0.7208 - 55ms/epoch - 5ms/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.5379 - accuracy: 0.7378 - val_loss: 0.4916 - val_accuracy: 0.7273 - 66ms/epoch - 7ms/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.5586 - accuracy: 0.7215 - val_loss: 0.4956 - val_accuracy: 0.7208 - 52ms/epoch - 5ms/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.5252 - accuracy: 0.7362 - val_loss: 0.4802 - val_accuracy: 0.7532 - 43ms/epoch - 4ms/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.5326 - accuracy: 0.7280 - val_loss: 0.5071 - val_accuracy: 0.6948 - 61ms/epoch - 6ms/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.5479 - accuracy: 0.7068 - val_loss: 0.4825 - val_accuracy: 0.7468 - 61ms/epoch - 6ms/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.5296 - accuracy: 0.7443 - val_loss: 0.5040 - val_accuracy: 0.7078 - 51ms/epoch - 5ms/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.5573 - accuracy: 0.7036 - val_loss: 0.4945 - val_accuracy: 0.7078 - 44ms/epoch - 4ms/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.5093 - accuracy: 0.7264 - val_loss: 0.5043 - val_accuracy: 0.7078 - 52ms/epoch - 5ms/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.5394 - accuracy: 0.7150 - val_loss: 0.5009 - val_accuracy: 0.7078 - 50ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.5326 - accuracy: 0.7231 - val_loss: 0.4738 - val_accuracy: 0.7532 - 46ms/epoch - 5ms/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.5259 - accuracy: 0.7280 - val_loss: 0.4911 - val_accuracy: 0.7143 - 60ms/epoch - 6ms/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.5038 - accuracy: 0.7459 - val_loss: 0.4647 - val_accuracy: 0.7987 - 60ms/epoch - 6ms/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.5136 - accuracy: 0.7313 - val_loss: 0.4615 - val_accuracy: 0.7987 - 56ms/epoch - 6ms/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.5216 - accuracy: 0.7345 - val_loss: 0.4887 - val_accuracy: 0.7857 - 49ms/epoch - 5ms/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.5289 - accuracy: 0.7231 - val_loss: 0.5212 - val_accuracy: 0.6948 - 43ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.5106 - accuracy: 0.7524 - val_loss: 0.4680 - val_accuracy: 0.7468 - 44ms/epoch - 4ms/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.5184 - accuracy: 0.7264 - val_loss: 0.4578 - val_accuracy: 0.7922 - 48ms/epoch - 5ms/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.5199 - accuracy: 0.7524 - val_loss: 0.4768 - val_accuracy: 0.7273 - 45ms/epoch - 5ms/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.5113 - accuracy: 0.7362 - val_loss: 0.4544 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.5210 - accuracy: 0.7443 - val_loss: 0.4579 - val_accuracy: 0.7922 - 47ms/epoch - 5ms/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.5084 - accuracy: 0.7573 - val_loss: 0.4619 - val_accuracy: 0.7597 - 52ms/epoch - 5ms/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.4963 - accuracy: 0.7671 - val_loss: 0.4519 - val_accuracy: 0.7922 - 71ms/epoch - 7ms/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.5165 - accuracy: 0.7394 - val_loss: 0.4504 - val_accuracy: 0.7922 - 52ms/epoch - 5ms/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.5004 - accuracy: 0.7557 - val_loss: 0.4465 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.5077 - accuracy: 0.7573 - val_loss: 0.4640 - val_accuracy: 0.7468 - 47ms/epoch - 5ms/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.5083 - accuracy: 0.7606 - val_loss: 0.4713 - val_accuracy: 0.7403 - 43ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.5153 - accuracy: 0.7362 - val_loss: 0.4724 - val_accuracy: 0.7338 - 46ms/epoch - 5ms/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.5178 - accuracy: 0.7476 - val_loss: 0.4529 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.4962 - accuracy: 0.7638 - val_loss: 0.4789 - val_accuracy: 0.7208 - 43ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.5136 - accuracy: 0.7394 - val_loss: 0.4583 - val_accuracy: 0.8117 - 43ms/epoch - 4ms/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.4921 - accuracy: 0.7557 - val_loss: 0.4469 - val_accuracy: 0.7922 - 43ms/epoch - 4ms/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.4970 - accuracy: 0.7508 - val_loss: 0.4445 - val_accuracy: 0.7987 - 49ms/epoch - 5ms/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.5090 - accuracy: 0.7541 - val_loss: 0.4841 - val_accuracy: 0.7208 - 46ms/epoch - 5ms/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.5003 - accuracy: 0.7671 - val_loss: 0.4773 - val_accuracy: 0.7338 - 49ms/epoch - 5ms/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.4900 - accuracy: 0.7655 - val_loss: 0.4658 - val_accuracy: 0.7468 - 45ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.4836 - val_accuracy: 0.7208 - 45ms/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.5180 - accuracy: 0.7557 - val_loss: 0.4555 - val_accuracy: 0.7662 - 48ms/epoch - 5ms/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.4813 - accuracy: 0.7687 - val_loss: 0.4456 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.5015 - accuracy: 0.7736 - val_loss: 0.4425 - val_accuracy: 0.7987 - 48ms/epoch - 5ms/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.5159 - accuracy: 0.7590 - val_loss: 0.4620 - val_accuracy: 0.7468 - 47ms/epoch - 5ms/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.4981 - accuracy: 0.7720 - val_loss: 0.4438 - val_accuracy: 0.7987 - 45ms/epoch - 5ms/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.4819 - accuracy: 0.7752 - val_loss: 0.4540 - val_accuracy: 0.7662 - 46ms/epoch - 5ms/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.5001 - accuracy: 0.7476 - val_loss: 0.4481 - val_accuracy: 0.8182 - 44ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.5028 - accuracy: 0.7557 - val_loss: 0.4548 - val_accuracy: 0.7597 - 46ms/epoch - 5ms/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.4951 - accuracy: 0.7606 - val_loss: 0.4621 - val_accuracy: 0.7468 - 51ms/epoch - 5ms/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.4911 - accuracy: 0.7606 - val_loss: 0.4461 - val_accuracy: 0.7857 - 44ms/epoch - 4ms/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.4891 - accuracy: 0.7476 - val_loss: 0.4584 - val_accuracy: 0.7468 - 45ms/epoch - 4ms/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.4966 - accuracy: 0.7606 - val_loss: 0.4458 - val_accuracy: 0.8052 - 49ms/epoch - 5ms/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.4977 - accuracy: 0.7606 - val_loss: 0.4521 - val_accuracy: 0.7792 - 51ms/epoch - 5ms/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.4965 - accuracy: 0.7638 - val_loss: 0.4478 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.4888 - accuracy: 0.7492 - val_loss: 0.4458 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.4871 - accuracy: 0.7459 - val_loss: 0.4685 - val_accuracy: 0.7468 - 48ms/epoch - 5ms/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.4804 - accuracy: 0.7704 - val_loss: 0.4730 - val_accuracy: 0.7273 - 48ms/epoch - 5ms/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.4953 - accuracy: 0.7524 - val_loss: 0.4516 - val_accuracy: 0.7727 - 50ms/epoch - 5ms/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.4798 - accuracy: 0.7720 - val_loss: 0.4421 - val_accuracy: 0.7987 - 50ms/epoch - 5ms/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.4854 - accuracy: 0.7557 - val_loss: 0.4651 - val_accuracy: 0.7403 - 51ms/epoch - 5ms/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.4917 - accuracy: 0.7736 - val_loss: 0.4407 - val_accuracy: 0.8052 - 46ms/epoch - 5ms/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.4860 - accuracy: 0.7638 - val_loss: 0.4387 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.4994 - accuracy: 0.7508 - val_loss: 0.4543 - val_accuracy: 0.7662 - 48ms/epoch - 5ms/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.5010 - accuracy: 0.7427 - val_loss: 0.4631 - val_accuracy: 0.7403 - 45ms/epoch - 5ms/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.4973 - accuracy: 0.7606 - val_loss: 0.4443 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.4972 - accuracy: 0.7736 - val_loss: 0.4419 - val_accuracy: 0.7922 - 49ms/epoch - 5ms/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.4914 - accuracy: 0.7557 - val_loss: 0.4419 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.5146 - accuracy: 0.7508 - val_loss: 0.4529 - val_accuracy: 0.7857 - 50ms/epoch - 5ms/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.5045 - accuracy: 0.7476 - val_loss: 0.4470 - val_accuracy: 0.7987 - 44ms/epoch - 4ms/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.5002 - accuracy: 0.7590 - val_loss: 0.4597 - val_accuracy: 0.7403 - 56ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.4951 - accuracy: 0.7752 - val_loss: 0.4503 - val_accuracy: 0.7857 - 45ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.4940 - accuracy: 0.7590 - val_loss: 0.4414 - val_accuracy: 0.7987 - 43ms/epoch - 4ms/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.4821 - accuracy: 0.7590 - val_loss: 0.4514 - val_accuracy: 0.7792 - 48ms/epoch - 5ms/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.4693 - accuracy: 0.7850 - val_loss: 0.4415 - val_accuracy: 0.7987 - 47ms/epoch - 5ms/step\n",
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.4956 - accuracy: 0.7638 - val_loss: 0.4451 - val_accuracy: 0.7987 - 45ms/epoch - 5ms/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.4976 - accuracy: 0.7476 - val_loss: 0.4537 - val_accuracy: 0.7532 - 48ms/epoch - 5ms/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.4880 - accuracy: 0.7704 - val_loss: 0.4368 - val_accuracy: 0.7987 - 44ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.4986 - accuracy: 0.7638 - val_loss: 0.4374 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.5037 - accuracy: 0.7655 - val_loss: 0.4435 - val_accuracy: 0.7922 - 47ms/epoch - 5ms/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.4985 - accuracy: 0.7508 - val_loss: 0.4502 - val_accuracy: 0.7727 - 47ms/epoch - 5ms/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.4952 - accuracy: 0.7638 - val_loss: 0.4436 - val_accuracy: 0.7987 - 47ms/epoch - 5ms/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.4804 - accuracy: 0.7655 - val_loss: 0.4455 - val_accuracy: 0.7987 - 44ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.4987 - accuracy: 0.7443 - val_loss: 0.4436 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.4806 - accuracy: 0.7638 - val_loss: 0.4442 - val_accuracy: 0.7987 - 47ms/epoch - 5ms/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.4926 - accuracy: 0.7606 - val_loss: 0.4413 - val_accuracy: 0.7987 - 48ms/epoch - 5ms/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.4832 - accuracy: 0.7655 - val_loss: 0.4681 - val_accuracy: 0.7403 - 45ms/epoch - 5ms/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.4912 - accuracy: 0.7638 - val_loss: 0.4420 - val_accuracy: 0.8117 - 46ms/epoch - 5ms/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.4876 - accuracy: 0.7720 - val_loss: 0.4591 - val_accuracy: 0.7403 - 48ms/epoch - 5ms/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.4869 - accuracy: 0.7704 - val_loss: 0.4474 - val_accuracy: 0.7857 - 49ms/epoch - 5ms/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.4965 - accuracy: 0.7557 - val_loss: 0.4497 - val_accuracy: 0.7727 - 49ms/epoch - 5ms/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.4955 - accuracy: 0.7541 - val_loss: 0.4517 - val_accuracy: 0.7662 - 50ms/epoch - 5ms/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.4729 - accuracy: 0.7769 - val_loss: 0.4362 - val_accuracy: 0.7922 - 45ms/epoch - 5ms/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.4888 - accuracy: 0.7769 - val_loss: 0.4471 - val_accuracy: 0.7792 - 46ms/epoch - 5ms/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.4935 - accuracy: 0.7655 - val_loss: 0.4425 - val_accuracy: 0.7987 - 48ms/epoch - 5ms/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.4899 - accuracy: 0.7606 - val_loss: 0.4484 - val_accuracy: 0.7857 - 46ms/epoch - 5ms/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.4950 - accuracy: 0.7801 - val_loss: 0.4503 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.4817 - accuracy: 0.7557 - val_loss: 0.4420 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.4843 - accuracy: 0.7671 - val_loss: 0.4513 - val_accuracy: 0.7662 - 45ms/epoch - 4ms/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.4818 - accuracy: 0.7638 - val_loss: 0.4385 - val_accuracy: 0.7987 - 48ms/epoch - 5ms/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.4890 - accuracy: 0.7524 - val_loss: 0.4446 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.4721 - accuracy: 0.7655 - val_loss: 0.4400 - val_accuracy: 0.7922 - 50ms/epoch - 5ms/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.4791 - accuracy: 0.7541 - val_loss: 0.4522 - val_accuracy: 0.7597 - 46ms/epoch - 5ms/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.4863 - accuracy: 0.7606 - val_loss: 0.4428 - val_accuracy: 0.7922 - 47ms/epoch - 5ms/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.4968 - accuracy: 0.7492 - val_loss: 0.4421 - val_accuracy: 0.7987 - 49ms/epoch - 5ms/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.4882 - accuracy: 0.7704 - val_loss: 0.4388 - val_accuracy: 0.7987 - 47ms/epoch - 5ms/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.4868 - accuracy: 0.7606 - val_loss: 0.4370 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.4807 - accuracy: 0.7573 - val_loss: 0.4371 - val_accuracy: 0.7922 - 42ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.4675 - accuracy: 0.7818 - val_loss: 0.4418 - val_accuracy: 0.7922 - 48ms/epoch - 5ms/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.4870 - accuracy: 0.7687 - val_loss: 0.4464 - val_accuracy: 0.7857 - 48ms/epoch - 5ms/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.4885 - accuracy: 0.7655 - val_loss: 0.4478 - val_accuracy: 0.7792 - 48ms/epoch - 5ms/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.4919 - accuracy: 0.7541 - val_loss: 0.4514 - val_accuracy: 0.7662 - 50ms/epoch - 5ms/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.4782 - accuracy: 0.7801 - val_loss: 0.4380 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.4979 - accuracy: 0.7394 - val_loss: 0.4492 - val_accuracy: 0.7727 - 45ms/epoch - 4ms/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.4807 - accuracy: 0.7720 - val_loss: 0.4410 - val_accuracy: 0.7922 - 43ms/epoch - 4ms/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.4811 - accuracy: 0.7622 - val_loss: 0.4460 - val_accuracy: 0.7857 - 48ms/epoch - 5ms/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.4873 - accuracy: 0.7671 - val_loss: 0.4488 - val_accuracy: 0.7727 - 45ms/epoch - 4ms/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.4813 - accuracy: 0.7785 - val_loss: 0.4378 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.4895 - accuracy: 0.7720 - val_loss: 0.4430 - val_accuracy: 0.7922 - 44ms/epoch - 4ms/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.5027 - accuracy: 0.7622 - val_loss: 0.4459 - val_accuracy: 0.7922 - 47ms/epoch - 5ms/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.4878 - accuracy: 0.7638 - val_loss: 0.4461 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.4764 - accuracy: 0.7769 - val_loss: 0.4571 - val_accuracy: 0.7403 - 44ms/epoch - 4ms/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.4851 - accuracy: 0.7638 - val_loss: 0.4438 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.4912 - accuracy: 0.7818 - val_loss: 0.4492 - val_accuracy: 0.7792 - 44ms/epoch - 4ms/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.4952 - accuracy: 0.7590 - val_loss: 0.4468 - val_accuracy: 0.7922 - 50ms/epoch - 5ms/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.4858 - accuracy: 0.7671 - val_loss: 0.4431 - val_accuracy: 0.7922 - 48ms/epoch - 5ms/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.4873 - accuracy: 0.7671 - val_loss: 0.4509 - val_accuracy: 0.7727 - 46ms/epoch - 5ms/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.4827 - accuracy: 0.7720 - val_loss: 0.4421 - val_accuracy: 0.7987 - 48ms/epoch - 5ms/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.4806 - accuracy: 0.7687 - val_loss: 0.4440 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.4872 - accuracy: 0.7590 - val_loss: 0.4468 - val_accuracy: 0.7857 - 45ms/epoch - 4ms/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.4849 - accuracy: 0.7557 - val_loss: 0.4474 - val_accuracy: 0.7792 - 50ms/epoch - 5ms/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.4910 - accuracy: 0.7557 - val_loss: 0.4433 - val_accuracy: 0.7922 - 50ms/epoch - 5ms/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.4750 - accuracy: 0.7736 - val_loss: 0.4437 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.4825 - accuracy: 0.7720 - val_loss: 0.4396 - val_accuracy: 0.7987 - 47ms/epoch - 5ms/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.4920 - accuracy: 0.7541 - val_loss: 0.4392 - val_accuracy: 0.7922 - 48ms/epoch - 5ms/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.4868 - accuracy: 0.7638 - val_loss: 0.4419 - val_accuracy: 0.7922 - 45ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.4887 - accuracy: 0.7492 - val_loss: 0.4389 - val_accuracy: 0.7922 - 48ms/epoch - 5ms/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.4711 - accuracy: 0.7818 - val_loss: 0.4390 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.4823 - accuracy: 0.7671 - val_loss: 0.4405 - val_accuracy: 0.7922 - 47ms/epoch - 5ms/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.4837 - accuracy: 0.7752 - val_loss: 0.4417 - val_accuracy: 0.7922 - 49ms/epoch - 5ms/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.5029 - accuracy: 0.7443 - val_loss: 0.4436 - val_accuracy: 0.7922 - 44ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.4813 - accuracy: 0.7687 - val_loss: 0.4482 - val_accuracy: 0.7727 - 47ms/epoch - 5ms/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.4823 - accuracy: 0.7638 - val_loss: 0.4439 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.4834 - accuracy: 0.7704 - val_loss: 0.4462 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.4806 - accuracy: 0.7801 - val_loss: 0.4422 - val_accuracy: 0.7922 - 49ms/epoch - 5ms/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.4751 - accuracy: 0.7769 - val_loss: 0.4434 - val_accuracy: 0.7857 - 46ms/epoch - 5ms/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.4783 - accuracy: 0.7606 - val_loss: 0.4510 - val_accuracy: 0.7662 - 46ms/epoch - 5ms/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.4803 - accuracy: 0.7622 - val_loss: 0.4411 - val_accuracy: 0.7987 - 46ms/epoch - 5ms/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.4851 - accuracy: 0.7736 - val_loss: 0.4426 - val_accuracy: 0.7922 - 52ms/epoch - 5ms/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.4775 - accuracy: 0.7671 - val_loss: 0.4379 - val_accuracy: 0.7922 - 43ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.4933 - accuracy: 0.7638 - val_loss: 0.4424 - val_accuracy: 0.7922 - 57ms/epoch - 6ms/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.5034 - accuracy: 0.7687 - val_loss: 0.4442 - val_accuracy: 0.7922 - 44ms/epoch - 4ms/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.4817 - accuracy: 0.7818 - val_loss: 0.4431 - val_accuracy: 0.7922 - 52ms/epoch - 5ms/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.4888 - accuracy: 0.7736 - val_loss: 0.4424 - val_accuracy: 0.7922 - 49ms/epoch - 5ms/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.4867 - accuracy: 0.7655 - val_loss: 0.4464 - val_accuracy: 0.7792 - 45ms/epoch - 4ms/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.4902 - accuracy: 0.7704 - val_loss: 0.4430 - val_accuracy: 0.7922 - 44ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.4773 - accuracy: 0.7850 - val_loss: 0.4447 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.4783 - accuracy: 0.7638 - val_loss: 0.4480 - val_accuracy: 0.7727 - 48ms/epoch - 5ms/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.4834 - accuracy: 0.7638 - val_loss: 0.4494 - val_accuracy: 0.7727 - 47ms/epoch - 5ms/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.4701 - accuracy: 0.7736 - val_loss: 0.4370 - val_accuracy: 0.7987 - 45ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.4784 - accuracy: 0.7736 - val_loss: 0.4414 - val_accuracy: 0.7922 - 49ms/epoch - 5ms/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.4841 - accuracy: 0.7524 - val_loss: 0.4453 - val_accuracy: 0.7792 - 44ms/epoch - 4ms/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.4749 - accuracy: 0.7785 - val_loss: 0.4491 - val_accuracy: 0.7727 - 48ms/epoch - 5ms/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.4904 - accuracy: 0.7573 - val_loss: 0.4455 - val_accuracy: 0.7792 - 43ms/epoch - 4ms/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.4942 - accuracy: 0.7720 - val_loss: 0.4422 - val_accuracy: 0.7922 - 42ms/epoch - 4ms/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.4745 - accuracy: 0.7834 - val_loss: 0.4470 - val_accuracy: 0.7727 - 50ms/epoch - 5ms/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.4937 - accuracy: 0.7736 - val_loss: 0.4430 - val_accuracy: 0.7922 - 43ms/epoch - 4ms/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.4990 - accuracy: 0.7736 - val_loss: 0.4507 - val_accuracy: 0.7662 - 47ms/epoch - 5ms/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.4821 - accuracy: 0.7769 - val_loss: 0.4430 - val_accuracy: 0.7857 - 51ms/epoch - 5ms/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.4767 - accuracy: 0.7671 - val_loss: 0.4415 - val_accuracy: 0.7922 - 44ms/epoch - 4ms/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.4801 - accuracy: 0.7720 - val_loss: 0.4404 - val_accuracy: 0.7922 - 45ms/epoch - 4ms/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.4697 - accuracy: 0.7704 - val_loss: 0.4380 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.4701 - accuracy: 0.7704 - val_loss: 0.4412 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n",
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.4762 - accuracy: 0.7720 - val_loss: 0.4421 - val_accuracy: 0.7857 - 55ms/epoch - 5ms/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.4756 - accuracy: 0.7606 - val_loss: 0.4392 - val_accuracy: 0.7857 - 47ms/epoch - 5ms/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.4661 - accuracy: 0.7818 - val_loss: 0.4409 - val_accuracy: 0.7922 - 46ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14043e4ceb0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train,train['Outcome'], epochs=200,verbose=2,validation_data=[scaled_test,val['Outcome']],batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 108)               13932     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 108)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 56)                6104      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 56)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 24)                1368      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,581\n",
      "Trainable params: 22,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
