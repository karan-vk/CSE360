{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df_churn.drop(['RowNumber','CustomerId','Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  8,  7,  4,  6,  3, 10,  5,  9,  0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh = ce.OneHotEncoder(cols=['Geography', 'Gender','NumOfProducts','Tenure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(cols=['Geography', 'Gender', 'NumOfProducts', 'Tenure'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneh.fit(df_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = oneh.transform(df_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography_1</th>\n",
       "      <th>Geography_2</th>\n",
       "      <th>Geography_3</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Gender_2</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure_1</th>\n",
       "      <th>Tenure_2</th>\n",
       "      <th>Tenure_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Tenure_11</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts_1</th>\n",
       "      <th>NumOfProducts_2</th>\n",
       "      <th>NumOfProducts_3</th>\n",
       "      <th>NumOfProducts_4</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.431698</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>0.306311</td>\n",
       "      <td>0.304626</td>\n",
       "      <td>0.30332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198993</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.160919</td>\n",
       "      <td>0.498341</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore   Geography_1   Geography_2   Geography_3      Gender_1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean     650.528800      0.501400      0.247700      0.250900      0.454300   \n",
       "std       96.653299      0.500023      0.431698      0.433553      0.497932   \n",
       "min      350.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      584.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      652.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%      718.000000      1.000000      0.000000      1.000000      1.000000   \n",
       "max      850.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           Gender_2           Age      Tenure_1      Tenure_2     Tenure_3  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.00000   \n",
       "mean       0.545700     38.921800      0.104800      0.103500      0.10250   \n",
       "std        0.497932     10.487806      0.306311      0.304626      0.30332   \n",
       "min        0.000000     18.000000      0.000000      0.000000      0.00000   \n",
       "25%        0.000000     32.000000      0.000000      0.000000      0.00000   \n",
       "50%        1.000000     37.000000      0.000000      0.000000      0.00000   \n",
       "75%        1.000000     44.000000      0.000000      0.000000      0.00000   \n",
       "max        1.000000     92.000000      1.000000      1.000000      1.00000   \n",
       "\n",
       "       ...     Tenure_11        Balance  NumOfProducts_1  NumOfProducts_2  \\\n",
       "count  ...  10000.000000   10000.000000     10000.000000     10000.000000   \n",
       "mean   ...      0.041300   76485.889288         0.508400         0.026600   \n",
       "std    ...      0.198993   62397.405202         0.499954         0.160919   \n",
       "min    ...      0.000000       0.000000         0.000000         0.000000   \n",
       "25%    ...      0.000000       0.000000         0.000000         0.000000   \n",
       "50%    ...      0.000000   97198.540000         1.000000         0.000000   \n",
       "75%    ...      0.000000  127644.240000         1.000000         0.000000   \n",
       "max    ...      1.000000  250898.090000         1.000000         1.000000   \n",
       "\n",
       "       NumOfProducts_3  NumOfProducts_4    HasCrCard  IsActiveMember  \\\n",
       "count     10000.000000     10000.000000  10000.00000    10000.000000   \n",
       "mean          0.459000         0.006000      0.70550        0.515100   \n",
       "std           0.498341         0.077231      0.45584        0.499797   \n",
       "min           0.000000         0.000000      0.00000        0.000000   \n",
       "25%           0.000000         0.000000      0.00000        0.000000   \n",
       "50%           0.000000         0.000000      1.00000        1.000000   \n",
       "75%           1.000000         0.000000      1.00000        1.000000   \n",
       "max           1.000000         1.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_cleaned[X_cleaned.drop('Exited',axis=1).columns], X_cleaned['Exited'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_transformer = Pipeline(steps=[\n",
    "        ('standard', StandardScaler())])\n",
    "\n",
    "minmax_transformer = Pipeline(steps=[\n",
    "        ('minmax', MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "        #     ('std', standard_transformer , ['']),\n",
    "            ('mm', minmax_transformer , ['CreditScore','Age','Balance'])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('mm',\n",
       "                                 Pipeline(steps=[('minmax', MinMaxScaler())]),\n",
       "                                 ['CreditScore', 'Age', 'Balance'])])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.38000000e-01, 3.24324324e-01, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.01348880e+05],\n",
       "       [5.16000000e-01, 3.10810811e-01, 3.34031479e-01, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.12542580e+05],\n",
       "       [3.04000000e-01, 3.24324324e-01, 6.36357176e-01, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 1.13931570e+05],\n",
       "       ...,\n",
       "       [6.52000000e-01, 3.91891892e-01, 5.28488148e-01, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 6.33282422e+03],\n",
       "       [7.30000000e-01, 2.56756757e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.22874904e+04],\n",
       "       [3.40000000e-01, 3.78378378e-01, 4.72029416e-01, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 8.28243599e+04]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = preprocessor.transform(X_resampled)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 26)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_final, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "                           tf.keras.layers.Dense(256,activation='tanh',input_shape=(26,)),\n",
    "                           tf.keras.layers.Dropout(0.1),\n",
    "                           tf.keras.layers.Dense(108,activation='relu'),\n",
    "                           tf.keras.layers.Dropout(0.3), \n",
    "                           tf.keras.layers.Dense(56,activation='tanh'),\n",
    "                           tf.keras.layers.Dropout(0.125),\n",
    "                           tf.keras.layers.Dense(24,activation='exponential'),\n",
    "                           tf.keras.layers.Dropout(0.3),\n",
    "                           tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6410\n",
       "0    6330\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karan\\miniconda3\\envs\\cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 1s - loss: 0.8848 - accuracy: 0.5091 - val_loss: 0.6956 - val_accuracy: 0.4874 - 1s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "200/200 - 1s - loss: 0.7840 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.4874 - 621ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 0.7600 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5126 - 578ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 0.7459 - accuracy: 0.4983 - val_loss: 0.6935 - val_accuracy: 0.4874 - 580ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "200/200 - 1s - loss: 0.7334 - accuracy: 0.4945 - val_loss: 0.6930 - val_accuracy: 0.5129 - 523ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 0.7272 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5119 - 551ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 0.7238 - accuracy: 0.4975 - val_loss: 0.6936 - val_accuracy: 0.4874 - 546ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 0.7258 - accuracy: 0.4956 - val_loss: 0.6939 - val_accuracy: 0.4874 - 553ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 0.7201 - accuracy: 0.4989 - val_loss: 0.6929 - val_accuracy: 0.5126 - 559ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "200/200 - 1s - loss: 0.7191 - accuracy: 0.4937 - val_loss: 0.6928 - val_accuracy: 0.5129 - 562ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 0.7166 - accuracy: 0.4974 - val_loss: 0.6942 - val_accuracy: 0.4874 - 516ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 0.7133 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.4874 - 551ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 0.7129 - accuracy: 0.4958 - val_loss: 0.6928 - val_accuracy: 0.5132 - 576ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 0.7125 - accuracy: 0.4973 - val_loss: 0.6954 - val_accuracy: 0.4874 - 591ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "200/200 - 1s - loss: 0.7099 - accuracy: 0.4952 - val_loss: 0.6930 - val_accuracy: 0.5129 - 525ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 0.7055 - accuracy: 0.5070 - val_loss: 0.6929 - val_accuracy: 0.5129 - 591ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "200/200 - 1s - loss: 0.7080 - accuracy: 0.4987 - val_loss: 0.6928 - val_accuracy: 0.5132 - 630ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "200/200 - 1s - loss: 0.7093 - accuracy: 0.4921 - val_loss: 0.6928 - val_accuracy: 0.5129 - 541ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 0.7056 - accuracy: 0.4995 - val_loss: 0.6929 - val_accuracy: 0.5129 - 500ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "200/200 - 1s - loss: 0.7055 - accuracy: 0.5005 - val_loss: 0.6929 - val_accuracy: 0.5129 - 512ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 0.7040 - accuracy: 0.4999 - val_loss: 0.6934 - val_accuracy: 0.4874 - 535ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 0.7059 - accuracy: 0.4961 - val_loss: 0.6936 - val_accuracy: 0.4874 - 509ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 0.7022 - accuracy: 0.5010 - val_loss: 0.6934 - val_accuracy: 0.4874 - 509ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "200/200 - 0s - loss: 0.7047 - accuracy: 0.4998 - val_loss: 0.6930 - val_accuracy: 0.5129 - 499ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "200/200 - 1s - loss: 0.7050 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5129 - 511ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "200/200 - 1s - loss: 0.7034 - accuracy: 0.4975 - val_loss: 0.6929 - val_accuracy: 0.5132 - 528ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 0.7020 - accuracy: 0.5086 - val_loss: 0.6936 - val_accuracy: 0.4874 - 638ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 0.7024 - accuracy: 0.4987 - val_loss: 0.6929 - val_accuracy: 0.5129 - 641ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 0.7016 - accuracy: 0.5072 - val_loss: 0.6930 - val_accuracy: 0.5126 - 559ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "200/200 - 1s - loss: 0.7010 - accuracy: 0.5011 - val_loss: 0.6944 - val_accuracy: 0.4874 - 513ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "200/200 - 0s - loss: 0.7042 - accuracy: 0.4930 - val_loss: 0.6937 - val_accuracy: 0.4874 - 499ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "200/200 - 0s - loss: 0.7000 - accuracy: 0.5040 - val_loss: 0.6948 - val_accuracy: 0.4874 - 496ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "200/200 - 0s - loss: 0.7014 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5122 - 476ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "200/200 - 1s - loss: 0.7014 - accuracy: 0.4931 - val_loss: 0.6929 - val_accuracy: 0.5132 - 503ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "200/200 - 0s - loss: 0.6996 - accuracy: 0.5075 - val_loss: 0.6938 - val_accuracy: 0.4874 - 495ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 0.7018 - accuracy: 0.4975 - val_loss: 0.6928 - val_accuracy: 0.5129 - 516ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 0.7008 - accuracy: 0.4926 - val_loss: 0.6930 - val_accuracy: 0.5129 - 508ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 0.7022 - accuracy: 0.4939 - val_loss: 0.6937 - val_accuracy: 0.4874 - 518ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 0.7017 - accuracy: 0.4943 - val_loss: 0.6930 - val_accuracy: 0.5129 - 512ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "200/200 - 1s - loss: 0.7002 - accuracy: 0.4980 - val_loss: 0.6929 - val_accuracy: 0.5129 - 530ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "200/200 - 1s - loss: 0.7007 - accuracy: 0.4954 - val_loss: 0.6928 - val_accuracy: 0.5129 - 504ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 0.6998 - accuracy: 0.4971 - val_loss: 0.6928 - val_accuracy: 0.5129 - 517ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 0.7009 - accuracy: 0.4937 - val_loss: 0.6934 - val_accuracy: 0.4874 - 510ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 0.6992 - accuracy: 0.4979 - val_loss: 0.6929 - val_accuracy: 0.5129 - 532ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "200/200 - 1s - loss: 0.6994 - accuracy: 0.4984 - val_loss: 0.6929 - val_accuracy: 0.5129 - 502ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 0.6981 - accuracy: 0.5060 - val_loss: 0.6929 - val_accuracy: 0.5132 - 516ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "200/200 - 1s - loss: 0.6987 - accuracy: 0.5019 - val_loss: 0.6928 - val_accuracy: 0.5129 - 515ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 0.6996 - accuracy: 0.4960 - val_loss: 0.6930 - val_accuracy: 0.5129 - 517ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 0.6975 - accuracy: 0.5084 - val_loss: 0.6929 - val_accuracy: 0.5126 - 503ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "200/200 - 1s - loss: 0.6995 - accuracy: 0.4956 - val_loss: 0.6938 - val_accuracy: 0.4874 - 516ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 0.6977 - accuracy: 0.5037 - val_loss: 0.6928 - val_accuracy: 0.5129 - 505ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 0.6991 - accuracy: 0.4953 - val_loss: 0.6937 - val_accuracy: 0.4874 - 516ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 0.6982 - accuracy: 0.5020 - val_loss: 0.6929 - val_accuracy: 0.5129 - 521ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "200/200 - 1s - loss: 0.6986 - accuracy: 0.4952 - val_loss: 0.6935 - val_accuracy: 0.5126 - 516ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "200/200 - 1s - loss: 0.6989 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.4874 - 519ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 0.6988 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5129 - 548ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "200/200 - 1s - loss: 0.6974 - accuracy: 0.5049 - val_loss: 0.6934 - val_accuracy: 0.4874 - 534ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "200/200 - 1s - loss: 0.6972 - accuracy: 0.5042 - val_loss: 0.6930 - val_accuracy: 0.5129 - 535ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "200/200 - 1s - loss: 0.6984 - accuracy: 0.4931 - val_loss: 0.6928 - val_accuracy: 0.5129 - 528ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "200/200 - 1s - loss: 0.6972 - accuracy: 0.5026 - val_loss: 0.6938 - val_accuracy: 0.4874 - 502ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "200/200 - 1s - loss: 0.6965 - accuracy: 0.5095 - val_loss: 0.6939 - val_accuracy: 0.4874 - 517ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "200/200 - 1s - loss: 0.6987 - accuracy: 0.4937 - val_loss: 0.6934 - val_accuracy: 0.4874 - 520ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "200/200 - 1s - loss: 0.6963 - accuracy: 0.4985 - val_loss: 0.6929 - val_accuracy: 0.5129 - 519ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "200/200 - 1s - loss: 0.6981 - accuracy: 0.5002 - val_loss: 0.6929 - val_accuracy: 0.5129 - 523ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "200/200 - 1s - loss: 0.6966 - accuracy: 0.5041 - val_loss: 0.6935 - val_accuracy: 0.4874 - 526ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "200/200 - 1s - loss: 0.6967 - accuracy: 0.5030 - val_loss: 0.6933 - val_accuracy: 0.4874 - 502ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "200/200 - 1s - loss: 0.6977 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5129 - 517ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "200/200 - 1s - loss: 0.6974 - accuracy: 0.4984 - val_loss: 0.6933 - val_accuracy: 0.4874 - 504ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "200/200 - 1s - loss: 0.6964 - accuracy: 0.5024 - val_loss: 0.6929 - val_accuracy: 0.5126 - 508ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "200/200 - 1s - loss: 0.6969 - accuracy: 0.5001 - val_loss: 0.6930 - val_accuracy: 0.5129 - 528ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "200/200 - 0s - loss: 0.6971 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4874 - 493ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "200/200 - 1s - loss: 0.6970 - accuracy: 0.4979 - val_loss: 0.6930 - val_accuracy: 0.5132 - 536ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "200/200 - 1s - loss: 0.6986 - accuracy: 0.4959 - val_loss: 0.6929 - val_accuracy: 0.5129 - 516ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "200/200 - 1s - loss: 0.6958 - accuracy: 0.5075 - val_loss: 0.6929 - val_accuracy: 0.5129 - 518ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "200/200 - 1s - loss: 0.6975 - accuracy: 0.4958 - val_loss: 0.6929 - val_accuracy: 0.5129 - 516ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "200/200 - 0s - loss: 0.6963 - accuracy: 0.5021 - val_loss: 0.6946 - val_accuracy: 0.4874 - 496ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "200/200 - 1s - loss: 0.6970 - accuracy: 0.4980 - val_loss: 0.6929 - val_accuracy: 0.5129 - 602ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "200/200 - 1s - loss: 0.6961 - accuracy: 0.5006 - val_loss: 0.6933 - val_accuracy: 0.4874 - 598ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "200/200 - 1s - loss: 0.6961 - accuracy: 0.4994 - val_loss: 0.6937 - val_accuracy: 0.4874 - 629ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "200/200 - 1s - loss: 0.6963 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.4874 - 688ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "200/200 - 1s - loss: 0.6947 - accuracy: 0.5121 - val_loss: 0.6937 - val_accuracy: 0.4874 - 596ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "200/200 - 1s - loss: 0.6961 - accuracy: 0.4993 - val_loss: 0.6939 - val_accuracy: 0.4874 - 587ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "200/200 - 1s - loss: 0.6964 - accuracy: 0.5020 - val_loss: 0.6929 - val_accuracy: 0.5126 - 511ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "200/200 - 1s - loss: 0.6956 - accuracy: 0.5049 - val_loss: 0.6929 - val_accuracy: 0.5129 - 591ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "200/200 - 1s - loss: 0.6961 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5126 - 584ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "200/200 - 1s - loss: 0.6964 - accuracy: 0.5003 - val_loss: 0.6946 - val_accuracy: 0.4874 - 523ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "200/200 - 1s - loss: 0.6967 - accuracy: 0.4967 - val_loss: 0.6928 - val_accuracy: 0.5126 - 535ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "200/200 - 1s - loss: 0.6960 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.4874 - 517ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "200/200 - 1s - loss: 0.6965 - accuracy: 0.4916 - val_loss: 0.6936 - val_accuracy: 0.4874 - 546ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "200/200 - 1s - loss: 0.6954 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.4874 - 516ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "200/200 - 1s - loss: 0.6958 - accuracy: 0.5009 - val_loss: 0.6929 - val_accuracy: 0.5129 - 526ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "200/200 - 1s - loss: 0.6967 - accuracy: 0.4973 - val_loss: 0.6929 - val_accuracy: 0.5129 - 566ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "200/200 - 1s - loss: 0.6957 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.4874 - 626ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "200/200 - 1s - loss: 0.6963 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.4874 - 563ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "200/200 - 1s - loss: 0.6963 - accuracy: 0.4984 - val_loss: 0.6943 - val_accuracy: 0.4874 - 568ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "200/200 - 1s - loss: 0.6965 - accuracy: 0.4975 - val_loss: 0.6937 - val_accuracy: 0.4874 - 559ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "200/200 - 0s - loss: 0.6954 - accuracy: 0.5075 - val_loss: 0.6930 - val_accuracy: 0.5129 - 489ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "200/200 - 0s - loss: 0.6965 - accuracy: 0.4994 - val_loss: 0.6929 - val_accuracy: 0.5126 - 476ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "200/200 - 1s - loss: 0.6976 - accuracy: 0.4932 - val_loss: 0.6935 - val_accuracy: 0.4874 - 501ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "200/200 - 1s - loss: 0.6958 - accuracy: 0.5044 - val_loss: 0.6928 - val_accuracy: 0.5129 - 503ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18db4fb4040>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=100,verbose=2,validation_data=[X_test,y_test],batch_size=64,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1633,    0],\n",
       "       [1552,    1]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred>0.5,1,0)\n",
    "tf.math.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677875</td>\n",
       "      <td>1633.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>1553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.512869</td>\n",
       "      <td>0.512869</td>\n",
       "      <td>0.512869</td>\n",
       "      <td>0.512869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.500322</td>\n",
       "      <td>0.339581</td>\n",
       "      <td>3186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.750240</td>\n",
       "      <td>0.512869</td>\n",
       "      <td>0.348075</td>\n",
       "      <td>3186.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.512716  1.000000  0.677875  1633.000000\n",
       "1              1.000000  0.000644  0.001287  1553.000000\n",
       "accuracy       0.512869  0.512869  0.512869     0.512869\n",
       "macro avg      0.756358  0.500322  0.339581  3186.000000\n",
       "weighted avg   0.750240  0.512869  0.348075  3186.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9678fcbbceb5ef7bd2be700e1ce0e75cd9a08123793b1fd2775eecef6b74d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
