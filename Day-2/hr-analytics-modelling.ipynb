{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-02-26T05:12:06.407179Z","iopub.status.busy":"2022-02-26T05:12:06.406455Z","iopub.status.idle":"2022-02-26T05:12:14.517622Z","shell.execute_reply":"2022-02-26T05:12:14.516789Z","shell.execute_reply.started":"2022-02-26T05:12:06.407129Z"},"trusted":true},"outputs":[],"source":["# !pip install category_encoders"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-02-26T05:35:33.229973Z","iopub.status.busy":"2022-02-26T05:35:33.229666Z","iopub.status.idle":"2022-02-26T05:35:33.848262Z","shell.execute_reply":"2022-02-26T05:35:33.847487Z","shell.execute_reply.started":"2022-02-26T05:35:33.229935Z"},"trusted":true},"outputs":[],"source":["# Importing Packages\n","import numpy as np\n","import pandas as pd \n","import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","import keras\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import category_encoders as ce\n","from imblearn.over_sampling import SMOTE\n","from tensorflow.keras import initializers\n","import seaborn as sns\n","from sklearn.metrics import classification_report,confusion_matrix"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:35:34.027466Z","iopub.status.busy":"2022-02-26T05:35:34.026880Z","iopub.status.idle":"2022-02-26T05:35:34.051131Z","shell.execute_reply":"2022-02-26T05:35:34.050558Z","shell.execute_reply.started":"2022-02-26T05:35:34.027428Z"},"trusted":true},"outputs":[],"source":["# Importing Data\n","df_hr = pd.read_csv(\"HR_comma_sep.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.566641Z","iopub.status.busy":"2022-02-26T05:12:14.566325Z","iopub.status.idle":"2022-02-26T05:12:14.586212Z","shell.execute_reply":"2022-02-26T05:12:14.585398Z","shell.execute_reply.started":"2022-02-26T05:12:14.566584Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>satisfaction_level</th>\n","      <th>last_evaluation</th>\n","      <th>number_project</th>\n","      <th>average_montly_hours</th>\n","      <th>time_spend_company</th>\n","      <th>Work_accident</th>\n","      <th>left</th>\n","      <th>promotion_last_5years</th>\n","      <th>sales</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.38</td>\n","      <td>0.53</td>\n","      <td>2</td>\n","      <td>157</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sales</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.80</td>\n","      <td>0.86</td>\n","      <td>5</td>\n","      <td>262</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sales</td>\n","      <td>medium</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.11</td>\n","      <td>0.88</td>\n","      <td>7</td>\n","      <td>272</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sales</td>\n","      <td>medium</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.72</td>\n","      <td>0.87</td>\n","      <td>5</td>\n","      <td>223</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sales</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.37</td>\n","      <td>0.52</td>\n","      <td>2</td>\n","      <td>159</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sales</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14994</th>\n","      <td>0.40</td>\n","      <td>0.57</td>\n","      <td>2</td>\n","      <td>151</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>support</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>14995</th>\n","      <td>0.37</td>\n","      <td>0.48</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>support</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>14996</th>\n","      <td>0.37</td>\n","      <td>0.53</td>\n","      <td>2</td>\n","      <td>143</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>support</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>14997</th>\n","      <td>0.11</td>\n","      <td>0.96</td>\n","      <td>6</td>\n","      <td>280</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>support</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>14998</th>\n","      <td>0.37</td>\n","      <td>0.52</td>\n","      <td>2</td>\n","      <td>158</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>support</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14999 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["       satisfaction_level  last_evaluation  number_project  \\\n","0                    0.38             0.53               2   \n","1                    0.80             0.86               5   \n","2                    0.11             0.88               7   \n","3                    0.72             0.87               5   \n","4                    0.37             0.52               2   \n","...                   ...              ...             ...   \n","14994                0.40             0.57               2   \n","14995                0.37             0.48               2   \n","14996                0.37             0.53               2   \n","14997                0.11             0.96               6   \n","14998                0.37             0.52               2   \n","\n","       average_montly_hours  time_spend_company  Work_accident  left  \\\n","0                       157                   3              0     1   \n","1                       262                   6              0     1   \n","2                       272                   4              0     1   \n","3                       223                   5              0     1   \n","4                       159                   3              0     1   \n","...                     ...                 ...            ...   ...   \n","14994                   151                   3              0     1   \n","14995                   160                   3              0     1   \n","14996                   143                   3              0     1   \n","14997                   280                   4              0     1   \n","14998                   158                   3              0     1   \n","\n","       promotion_last_5years    sales  salary  \n","0                          0    sales     low  \n","1                          0    sales  medium  \n","2                          0    sales  medium  \n","3                          0    sales     low  \n","4                          0    sales     low  \n","...                      ...      ...     ...  \n","14994                      0  support     low  \n","14995                      0  support     low  \n","14996                      0  support     low  \n","14997                      0  support     low  \n","14998                      0  support     low  \n","\n","[14999 rows x 10 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Data Overview\n","df_hr"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.587704Z","iopub.status.busy":"2022-02-26T05:12:14.587414Z","iopub.status.idle":"2022-02-26T05:12:14.592602Z","shell.execute_reply":"2022-02-26T05:12:14.592016Z","shell.execute_reply.started":"2022-02-26T05:12:14.587667Z"},"trusted":true},"outputs":[],"source":["# One hot encoding\n","def one_hot_encoding(df,col):\n","    one_hot_encoder=ce.OneHotEncoder(cols=col,return_df=True,use_cat_names=True)\n","    df_final = one_hot_encoder.fit_transform(df)\n","    return df_final"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.594062Z","iopub.status.busy":"2022-02-26T05:12:14.593840Z","iopub.status.idle":"2022-02-26T05:12:14.601277Z","shell.execute_reply":"2022-02-26T05:12:14.600642Z","shell.execute_reply.started":"2022-02-26T05:12:14.594036Z"},"trusted":true},"outputs":[],"source":["def ordinal_encoding(df,col,mapping):\n","    ordinal_encoder=ce.OrdinalEncoder(cols=col,return_df=True,mapping=[{'col':col,'mapping':mapping}])\n","    df_final = ordinal_encoder.fit_transform(df)\n","    return df_final"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.602457Z","iopub.status.busy":"2022-02-26T05:12:14.602284Z","iopub.status.idle":"2022-02-26T05:12:14.638976Z","shell.execute_reply":"2022-02-26T05:12:14.638254Z","shell.execute_reply.started":"2022-02-26T05:12:14.602435Z"},"trusted":true},"outputs":[],"source":["df_hr_one_hot = one_hot_encoding(df_hr,\"sales\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.642353Z","iopub.status.busy":"2022-02-26T05:12:14.642125Z","iopub.status.idle":"2022-02-26T05:12:14.670347Z","shell.execute_reply":"2022-02-26T05:12:14.669775Z","shell.execute_reply.started":"2022-02-26T05:12:14.642327Z"},"trusted":true},"outputs":[],"source":["df_hr_one_hot = one_hot_encoding(df_hr_one_hot,\"salary\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.672061Z","iopub.status.busy":"2022-02-26T05:12:14.671785Z","iopub.status.idle":"2022-02-26T05:12:14.679221Z","shell.execute_reply":"2022-02-26T05:12:14.678429Z","shell.execute_reply.started":"2022-02-26T05:12:14.672017Z"},"trusted":true},"outputs":[],"source":["df_final = df_hr_one_hot.copy()\n","X = df_final.drop([\"left\"],axis = 1)\n","Y = df_final[[\"left\"]]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.681770Z","iopub.status.busy":"2022-02-26T05:12:14.681502Z","iopub.status.idle":"2022-02-26T05:12:14.692114Z","shell.execute_reply":"2022-02-26T05:12:14.691303Z","shell.execute_reply.started":"2022-02-26T05:12:14.681742Z"},"trusted":true},"outputs":[{"data":{"text/plain":["left\n","0       11428\n","1        3571\n","dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["Y.value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.694050Z","iopub.status.busy":"2022-02-26T05:12:14.693521Z","iopub.status.idle":"2022-02-26T05:12:14.761753Z","shell.execute_reply":"2022-02-26T05:12:14.761137Z","shell.execute_reply.started":"2022-02-26T05:12:14.694008Z"},"trusted":true},"outputs":[],"source":["smote = SMOTE()\n","X, Y = smote.fit_resample(X, Y)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T05:12:14.763238Z","iopub.status.busy":"2022-02-26T05:12:14.762650Z","iopub.status.idle":"2022-02-26T05:12:14.768961Z","shell.execute_reply":"2022-02-26T05:12:14.768121Z","shell.execute_reply.started":"2022-02-26T05:12:14.763208Z"},"trusted":true},"outputs":[],"source":["# Plotting accuracy of train,test\n","def plot_metric(history, metric):\n","    train_metrics = history.history[metric]\n","    val_metrics = history.history['val_'+metric]\n","    epochs = range(1, len(train_metrics) + 1)\n","    plt.plot(epochs, train_metrics)\n","    plt.plot(epochs, val_metrics)\n","    plt.title('Training and validation '+ metric)\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(metric)\n","    plt.legend([\"train_\"+metric, 'val_'+metric])\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T06:22:49.222707Z","iopub.status.busy":"2022-02-26T06:22:49.222412Z","iopub.status.idle":"2022-02-26T06:22:49.235921Z","shell.execute_reply":"2022-02-26T06:22:49.234976Z","shell.execute_reply.started":"2022-02-26T06:22:49.222673Z"},"trusted":true},"outputs":[],"source":["def train_nn(test_ratio,optimizer,epochs,batch_size):\n","    X_train, X_test,y_train,y_test = train_test_split(X,Y,test_size = test_ratio,random_state = 27)\n","    scaler = MinMaxScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    class myCallback(tf.keras.callbacks.Callback):\n","        def on_epoch_end(self,epoch,logs={}):\n","            if(logs.get(\"val_accuracy\")>98.2):\n","                  print(\"Reached the accuracy required (ie) 90%\", logs)\n","                  self.model.stop_training=True\n","    callback=myCallback()\n","    model = Sequential()\n","    model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n","    model.add(Dropout(0.05))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.05))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.05))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(16, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(optimizer = optimizer,\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[\"accuracy\"])\n","    history = model.fit(X_train,y_train,epochs=epochs,validation_data=(X_test,y_test),batch_size = batch_size,callbacks=[callback])\n","    print(f\"For {optimizer} with Batch Size {batch_size} \\n\")\n","    plot_metric(history,\"accuracy\")\n","    \n","    Y_pred = model.predict(X_test)\n","    Y_pred = np.round(Y_pred)\n","    sns.heatmap(confusion_matrix(Y_pred,y_test),annot = True, fmt='g')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T06:22:50.021175Z","iopub.status.busy":"2022-02-26T06:22:50.020901Z","iopub.status.idle":"2022-02-26T06:35:38.708029Z","shell.execute_reply":"2022-02-26T06:35:38.707176Z","shell.execute_reply.started":"2022-02-26T06:22:50.021141Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Karan\\miniconda3\\envs\\cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["72/72 [==============================] - 1s 9ms/step - loss: 0.4257 - accuracy: 0.8062 - val_loss: 0.1981 - val_accuracy: 0.9302\n","Epoch 2/1000\n"," 8/72 [==>...........................] - ETA: 0s - loss: 0.2290 - accuracy: 0.9150"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Karan\\miniconda3\\envs\\cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["72/72 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9317 - val_loss: 0.1745 - val_accuracy: 0.9401\n","Epoch 3/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9472 - val_loss: 0.1322 - val_accuracy: 0.9582\n","Epoch 4/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.1466 - accuracy: 0.9530 - val_loss: 0.1278 - val_accuracy: 0.9593\n","Epoch 5/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9549 - val_loss: 0.1321 - val_accuracy: 0.9578\n","Epoch 6/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1270 - accuracy: 0.9578 - val_loss: 0.1135 - val_accuracy: 0.9613\n","Epoch 7/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9597 - val_loss: 0.1086 - val_accuracy: 0.9637\n","Epoch 8/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.9609 - val_loss: 0.1053 - val_accuracy: 0.9659\n","Epoch 9/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9634 - val_loss: 0.1134 - val_accuracy: 0.9630\n","Epoch 10/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9636 - val_loss: 0.0994 - val_accuracy: 0.9659\n","Epoch 11/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.1005 - accuracy: 0.9653 - val_loss: 0.1090 - val_accuracy: 0.9665\n","Epoch 12/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9689 - val_loss: 0.1076 - val_accuracy: 0.9646\n","Epoch 13/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0930 - accuracy: 0.9694 - val_loss: 0.0988 - val_accuracy: 0.9698\n","Epoch 14/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9715 - val_loss: 0.0958 - val_accuracy: 0.9681\n","Epoch 15/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0866 - accuracy: 0.9713 - val_loss: 0.1026 - val_accuracy: 0.9700\n","Epoch 16/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0813 - accuracy: 0.9734 - val_loss: 0.0943 - val_accuracy: 0.9687\n","Epoch 17/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 0.0922 - val_accuracy: 0.9687\n","Epoch 18/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9745 - val_loss: 0.0944 - val_accuracy: 0.9678\n","Epoch 19/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 0.0910 - val_accuracy: 0.9718\n","Epoch 20/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.0998 - val_accuracy: 0.9703\n","Epoch 21/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0655 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9738\n","Epoch 22/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.0924 - val_accuracy: 0.9722\n","Epoch 23/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.0811 - val_accuracy: 0.9729\n","Epoch 24/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.0880 - val_accuracy: 0.9744\n","Epoch 25/1000\n","72/72 [==============================] - 1s 8ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 0.0925 - val_accuracy: 0.9707\n","Epoch 26/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0809 - val_accuracy: 0.9729\n","Epoch 27/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 0.0829 - val_accuracy: 0.9722\n","Epoch 28/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0559 - accuracy: 0.9800 - val_loss: 0.0818 - val_accuracy: 0.9751\n","Epoch 29/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0800 - val_accuracy: 0.9759\n","Epoch 30/1000\n","72/72 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 0.0790 - val_accuracy: 0.9766\n","Epoch 31/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9842 - val_loss: 0.0852 - val_accuracy: 0.9770\n","Epoch 32/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9835 - val_loss: 0.0835 - val_accuracy: 0.9722\n","Epoch 33/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0804 - val_accuracy: 0.9797\n","Epoch 34/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9819 - val_loss: 0.0823 - val_accuracy: 0.9757\n","Epoch 35/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.1022 - val_accuracy: 0.9722\n","Epoch 36/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9823 - val_loss: 0.0806 - val_accuracy: 0.9775\n","Epoch 37/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.0905 - val_accuracy: 0.9742\n","Epoch 38/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.0801 - val_accuracy: 0.9770\n","Epoch 39/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0419 - accuracy: 0.9854 - val_loss: 0.0866 - val_accuracy: 0.9770\n","Epoch 40/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.0777 - val_accuracy: 0.9792\n","Epoch 41/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0804 - val_accuracy: 0.9801\n","Epoch 42/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.0786 - val_accuracy: 0.9779\n","Epoch 43/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.0863 - val_accuracy: 0.9786\n","Epoch 44/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0960 - val_accuracy: 0.9773\n","Epoch 45/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.0873 - val_accuracy: 0.9762\n","Epoch 46/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.0887 - val_accuracy: 0.9797\n","Epoch 47/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9885 - val_loss: 0.0875 - val_accuracy: 0.9773\n","Epoch 48/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0913 - val_accuracy: 0.9766\n","Epoch 49/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9886 - val_loss: 0.0956 - val_accuracy: 0.9775\n","Epoch 50/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 0.0896 - val_accuracy: 0.9773\n","Epoch 51/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.0975 - val_accuracy: 0.9788\n","Epoch 52/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.0940 - val_accuracy: 0.9777\n","Epoch 53/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 0.0843 - val_accuracy: 0.9768\n","Epoch 54/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0900 - val_accuracy: 0.9777\n","Epoch 55/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.0983 - val_accuracy: 0.9768\n","Epoch 56/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.0849 - val_accuracy: 0.9788\n","Epoch 57/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9781\n","Epoch 58/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0910 - val_accuracy: 0.9788\n","Epoch 59/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.1017 - val_accuracy: 0.9746\n","Epoch 60/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9898 - val_loss: 0.0844 - val_accuracy: 0.9794\n","Epoch 61/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0911 - val_accuracy: 0.9786\n","Epoch 62/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0941 - val_accuracy: 0.9812\n","Epoch 63/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.1097 - val_accuracy: 0.9773\n","Epoch 64/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9876 - val_loss: 0.0933 - val_accuracy: 0.9759\n","Epoch 65/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.0939 - val_accuracy: 0.9773\n","Epoch 66/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.1018 - val_accuracy: 0.9781\n","Epoch 67/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.1039 - val_accuracy: 0.9781\n","Epoch 68/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.0955 - val_accuracy: 0.9779\n","Epoch 69/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.0956 - val_accuracy: 0.9797\n","Epoch 70/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9910 - val_loss: 0.0954 - val_accuracy: 0.9801\n","Epoch 71/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.1024 - val_accuracy: 0.9790\n","Epoch 72/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0992 - val_accuracy: 0.9812\n","Epoch 73/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.1030 - val_accuracy: 0.9775\n","Epoch 74/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.1089 - val_accuracy: 0.9786\n","Epoch 75/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.1079 - val_accuracy: 0.9768\n","Epoch 76/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0994 - val_accuracy: 0.9794\n","Epoch 77/1000\n","72/72 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 0.1073 - val_accuracy: 0.9764\n","Epoch 78/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.1082 - val_accuracy: 0.9777\n","Epoch 79/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0975 - val_accuracy: 0.9779\n","Epoch 80/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1105 - val_accuracy: 0.9757\n","Epoch 81/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.1093 - val_accuracy: 0.9766\n","Epoch 82/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.1031 - val_accuracy: 0.9799\n","Epoch 83/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.1041 - val_accuracy: 0.9762\n","Epoch 84/1000\n","72/72 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.1033 - val_accuracy: 0.9786\n","Epoch 85/1000\n","72/72 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.1201 - val_accuracy: 0.9742\n","Epoch 86/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.1067 - val_accuracy: 0.9801\n","Epoch 87/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.1112 - val_accuracy: 0.9779\n","Epoch 88/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.1140 - val_accuracy: 0.9777\n","Epoch 89/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.1018 - val_accuracy: 0.9797\n","Epoch 90/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.1044 - val_accuracy: 0.9779\n","Epoch 91/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.1127 - val_accuracy: 0.9764\n","Epoch 92/1000\n","72/72 [==============================] - 1s 8ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.1112 - val_accuracy: 0.9762\n","Epoch 93/1000\n","72/72 [==============================] - 1s 7ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.1026 - val_accuracy: 0.9792\n","Epoch 94/1000\n"," 1/72 [..............................] - ETA: 0s - loss: 0.0150 - accuracy: 0.9961"]}],"source":["Y_pred = train_nn(0.2,\"adam\",1000,256)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":4}
