{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       272                   4              0     1   \n",
       "3                       223                   5              0     1   \n",
       "4                       159                   3              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14994                   151                   3              0     1   \n",
       "14995                   160                   3              0     1   \n",
       "14996                   143                   3              0     1   \n",
       "14997                   280                   4              0     1   \n",
       "14998                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years    sales  salary  \n",
       "0                          0    sales     low  \n",
       "1                          0    sales  medium  \n",
       "2                          0    sales  medium  \n",
       "3                          0    sales     low  \n",
       "4                          0    sales     low  \n",
       "...                      ...      ...     ...  \n",
       "14994                      0  support     low  \n",
       "14995                      0  support     low  \n",
       "14996                      0  support     low  \n",
       "14997                      0  support     low  \n",
       "14998                      0  support     low  \n",
       "\n",
       "[14999 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh = ce.OneHotEncoder(cols=['sales', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(cols=['sales', 'salary'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneh.fit(df_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = oneh.transform(df_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales_1</th>\n",
       "      <th>sales_2</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_4</th>\n",
       "      <th>sales_5</th>\n",
       "      <th>sales_6</th>\n",
       "      <th>sales_7</th>\n",
       "      <th>sales_8</th>\n",
       "      <th>sales_9</th>\n",
       "      <th>sales_10</th>\n",
       "      <th>salary_1</th>\n",
       "      <th>salary_2</th>\n",
       "      <th>salary_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>3.803054</td>\n",
       "      <td>201.050337</td>\n",
       "      <td>3.498233</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.051137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.148610</td>\n",
       "      <td>0.042003</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>0.060137</td>\n",
       "      <td>0.057204</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>0.487766</td>\n",
       "      <td>0.429762</td>\n",
       "      <td>0.082472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248631</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>1.232592</td>\n",
       "      <td>49.943099</td>\n",
       "      <td>1.460136</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.425924</td>\n",
       "      <td>0.144281</td>\n",
       "      <td>0.447041</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385317</td>\n",
       "      <td>0.355715</td>\n",
       "      <td>0.200602</td>\n",
       "      <td>0.274077</td>\n",
       "      <td>0.237749</td>\n",
       "      <td>0.232239</td>\n",
       "      <td>0.222981</td>\n",
       "      <td>0.499867</td>\n",
       "      <td>0.495059</td>\n",
       "      <td>0.275092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "count        14999.000000     14999.000000    14999.000000   \n",
       "mean             0.612834         0.716102        3.803054   \n",
       "std              0.248631         0.171169        1.232592   \n",
       "min              0.090000         0.360000        2.000000   \n",
       "25%              0.440000         0.560000        3.000000   \n",
       "50%              0.640000         0.720000        4.000000   \n",
       "75%              0.820000         0.870000        5.000000   \n",
       "max              1.000000         1.000000        7.000000   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
       "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
       "mean             201.050337            3.498233       0.144610      0.238083   \n",
       "std               49.943099            1.460136       0.351719      0.425924   \n",
       "min               96.000000            2.000000       0.000000      0.000000   \n",
       "25%              156.000000            3.000000       0.000000      0.000000   \n",
       "50%              200.000000            3.000000       0.000000      0.000000   \n",
       "75%              245.000000            4.000000       0.000000      0.000000   \n",
       "max              310.000000           10.000000       1.000000      1.000000   \n",
       "\n",
       "       promotion_last_5years       sales_1       sales_2  ...       sales_4  \\\n",
       "count           14999.000000  14999.000000  14999.000000  ...  14999.000000   \n",
       "mean                0.021268      0.276018      0.051137  ...      0.181345   \n",
       "std                 0.144281      0.447041      0.220284  ...      0.385317   \n",
       "min                 0.000000      0.000000      0.000000  ...      0.000000   \n",
       "25%                 0.000000      0.000000      0.000000  ...      0.000000   \n",
       "50%                 0.000000      0.000000      0.000000  ...      0.000000   \n",
       "75%                 0.000000      1.000000      0.000000  ...      0.000000   \n",
       "max                 1.000000      1.000000      1.000000  ...      1.000000   \n",
       "\n",
       "            sales_5       sales_6       sales_7       sales_8       sales_9  \\\n",
       "count  14999.000000  14999.000000  14999.000000  14999.000000  14999.000000   \n",
       "mean       0.148610      0.042003      0.081805      0.060137      0.057204   \n",
       "std        0.355715      0.200602      0.274077      0.237749      0.232239   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           sales_10      salary_1      salary_2      salary_3  \n",
       "count  14999.000000  14999.000000  14999.000000  14999.000000  \n",
       "mean       0.052470      0.487766      0.429762      0.082472  \n",
       "std        0.222981      0.499867      0.495059      0.275092  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      1.000000      1.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_transformer = Pipeline(steps=[\n",
    "    ('standard', StandardScaler())])\n",
    "\n",
    "minmax_transformer = Pipeline(steps=[\n",
    "    ('minmax', MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    remainder='passthrough',  # passthough features not listed\n",
    "    transformers=[\n",
    "        ('std', standard_transforme4r, [\n",
    "         'last_evaluation', 'satisfaction_level', 'Work_accident']),\n",
    "        ('mm', minmax_transformer, ['number_project',\n",
    "         'average_montly_hours', 'time_spend_company'])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('std',\n",
       "                                 Pipeline(steps=[('standard',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['last_evaluation', 'satisfaction_level',\n",
       "                                  'Work_accident']),\n",
       "                                ('mm',\n",
       "                                 Pipeline(steps=[('minmax', MinMaxScaler())]),\n",
       "                                 ['number_project', 'average_montly_hours',\n",
       "                                  'time_spend_company'])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_cleaned.drop('left',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08727529, -0.93649469, -0.41116529, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.84070693,  0.75281433, -0.41116529, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.95755433, -2.02247906, -0.41116529, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.08727529, -0.97671633, -0.41116529, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.42494396, -2.02247906, -0.41116529, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.14569899, -0.97671633, -0.41116529, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = preprocessor.transform(X_cleaned.drop('left',axis=1))\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_final, X_cleaned['left'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "                           tf.keras.layers.Dense(256,activation='tanh',input_shape=(20,)),\n",
    "                           tf.keras.layers.Dropout(0.1),\n",
    "                           tf.keras.layers.Dense(108,activation='relu'),\n",
    "                           tf.keras.layers.Dropout(0.3), \n",
    "                           tf.keras.layers.Dense(56,activation='tanh'),\n",
    "                           tf.keras.layers.Dropout(0.125),\n",
    "                           tf.keras.layers.Dense(24,activation='exponential'),\n",
    "                           tf.keras.layers.Dropout(0.3),\n",
    "                           tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.999)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 - 1s - loss: 0.1606 - accuracy: 0.9499 - val_loss: 0.1479 - val_accuracy: 0.9560 - 1s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "188/188 - 1s - loss: 0.1599 - accuracy: 0.9485 - val_loss: 0.1439 - val_accuracy: 0.9627 - 551ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "188/188 - 1s - loss: 0.1591 - accuracy: 0.9517 - val_loss: 0.1942 - val_accuracy: 0.9360 - 542ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "188/188 - 1s - loss: 0.1534 - accuracy: 0.9519 - val_loss: 0.2103 - val_accuracy: 0.9170 - 573ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "188/188 - 1s - loss: 0.1555 - accuracy: 0.9505 - val_loss: 0.1685 - val_accuracy: 0.9460 - 538ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "188/188 - 1s - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.1496 - val_accuracy: 0.9580 - 774ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "188/188 - 1s - loss: 0.1457 - accuracy: 0.9570 - val_loss: 0.1376 - val_accuracy: 0.9600 - 578ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "188/188 - 1s - loss: 0.1430 - accuracy: 0.9563 - val_loss: 0.1379 - val_accuracy: 0.9623 - 559ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "188/188 - 1s - loss: 0.1408 - accuracy: 0.9564 - val_loss: 0.1361 - val_accuracy: 0.9630 - 577ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "188/188 - 1s - loss: 0.1471 - accuracy: 0.9557 - val_loss: 0.1387 - val_accuracy: 0.9633 - 546ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "188/188 - 1s - loss: 0.1433 - accuracy: 0.9562 - val_loss: 0.1335 - val_accuracy: 0.9630 - 634ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "188/188 - 1s - loss: 0.1410 - accuracy: 0.9574 - val_loss: 0.1341 - val_accuracy: 0.9627 - 540ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "188/188 - 1s - loss: 0.1450 - accuracy: 0.9580 - val_loss: 0.1302 - val_accuracy: 0.9653 - 563ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "188/188 - 1s - loss: 0.1370 - accuracy: 0.9593 - val_loss: 0.1279 - val_accuracy: 0.9647 - 562ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "188/188 - 1s - loss: 0.1380 - accuracy: 0.9588 - val_loss: 0.1302 - val_accuracy: 0.9650 - 558ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "188/188 - 1s - loss: 0.1300 - accuracy: 0.9609 - val_loss: 0.1264 - val_accuracy: 0.9650 - 559ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "188/188 - 1s - loss: 0.1334 - accuracy: 0.9617 - val_loss: 0.1310 - val_accuracy: 0.9667 - 562ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "188/188 - 1s - loss: 0.1301 - accuracy: 0.9619 - val_loss: 0.1334 - val_accuracy: 0.9647 - 588ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "188/188 - 1s - loss: 0.1306 - accuracy: 0.9590 - val_loss: 0.1298 - val_accuracy: 0.9667 - 619ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "188/188 - 1s - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.1274 - val_accuracy: 0.9650 - 590ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "188/188 - 1s - loss: 0.1301 - accuracy: 0.9622 - val_loss: 0.1234 - val_accuracy: 0.9677 - 573ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "188/188 - 1s - loss: 0.1296 - accuracy: 0.9603 - val_loss: 0.1264 - val_accuracy: 0.9630 - 574ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "188/188 - 1s - loss: 0.1274 - accuracy: 0.9623 - val_loss: 0.1302 - val_accuracy: 0.9647 - 580ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "188/188 - 1s - loss: 0.1292 - accuracy: 0.9614 - val_loss: 0.1309 - val_accuracy: 0.9630 - 546ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "188/188 - 1s - loss: 0.1218 - accuracy: 0.9637 - val_loss: 0.1274 - val_accuracy: 0.9647 - 532ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "188/188 - 1s - loss: 0.1269 - accuracy: 0.9632 - val_loss: 0.1277 - val_accuracy: 0.9633 - 555ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "188/188 - 1s - loss: 0.1183 - accuracy: 0.9646 - val_loss: 0.1292 - val_accuracy: 0.9637 - 596ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "188/188 - 1s - loss: 0.1238 - accuracy: 0.9629 - val_loss: 0.1483 - val_accuracy: 0.9473 - 980ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "188/188 - 1s - loss: 0.1200 - accuracy: 0.9634 - val_loss: 0.1262 - val_accuracy: 0.9660 - 609ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "188/188 - 1s - loss: 0.1229 - accuracy: 0.9630 - val_loss: 0.1258 - val_accuracy: 0.9663 - 549ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "188/188 - 1s - loss: 0.1191 - accuracy: 0.9644 - val_loss: 0.1247 - val_accuracy: 0.9637 - 583ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "188/188 - 1s - loss: 0.1231 - accuracy: 0.9634 - val_loss: 0.1252 - val_accuracy: 0.9663 - 555ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "188/188 - 1s - loss: 0.1193 - accuracy: 0.9642 - val_loss: 0.1216 - val_accuracy: 0.9667 - 542ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "188/188 - 1s - loss: 0.1189 - accuracy: 0.9636 - val_loss: 0.1182 - val_accuracy: 0.9667 - 524ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "188/188 - 1s - loss: 0.1162 - accuracy: 0.9644 - val_loss: 0.1212 - val_accuracy: 0.9667 - 540ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "188/188 - 1s - loss: 0.1191 - accuracy: 0.9648 - val_loss: 0.1223 - val_accuracy: 0.9677 - 627ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "188/188 - 1s - loss: 0.1181 - accuracy: 0.9647 - val_loss: 0.1274 - val_accuracy: 0.9657 - 605ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "188/188 - 1s - loss: 0.1174 - accuracy: 0.9651 - val_loss: 0.1174 - val_accuracy: 0.9670 - 553ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "188/188 - 1s - loss: 0.1149 - accuracy: 0.9652 - val_loss: 0.1171 - val_accuracy: 0.9687 - 517ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "188/188 - 1s - loss: 0.1187 - accuracy: 0.9630 - val_loss: 0.1298 - val_accuracy: 0.9630 - 543ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "188/188 - 1s - loss: 0.1157 - accuracy: 0.9641 - val_loss: 0.1142 - val_accuracy: 0.9677 - 522ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "188/188 - 1s - loss: 0.1147 - accuracy: 0.9671 - val_loss: 0.1171 - val_accuracy: 0.9673 - 1s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "188/188 - 1s - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.1366 - val_accuracy: 0.9587 - 606ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "188/188 - 1s - loss: 0.1138 - accuracy: 0.9670 - val_loss: 0.1178 - val_accuracy: 0.9677 - 566ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "188/188 - 1s - loss: 0.1146 - accuracy: 0.9641 - val_loss: 0.1240 - val_accuracy: 0.9667 - 532ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "188/188 - 1s - loss: 0.1112 - accuracy: 0.9670 - val_loss: 0.1186 - val_accuracy: 0.9687 - 563ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "188/188 - 1s - loss: 0.1150 - accuracy: 0.9653 - val_loss: 0.1199 - val_accuracy: 0.9687 - 561ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "188/188 - 1s - loss: 0.1082 - accuracy: 0.9677 - val_loss: 0.1179 - val_accuracy: 0.9653 - 531ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "188/188 - 1s - loss: 0.1079 - accuracy: 0.9661 - val_loss: 0.1468 - val_accuracy: 0.9613 - 552ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "188/188 - 1s - loss: 0.1082 - accuracy: 0.9669 - val_loss: 0.1219 - val_accuracy: 0.9667 - 556ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "188/188 - 1s - loss: 0.1109 - accuracy: 0.9663 - val_loss: 0.1135 - val_accuracy: 0.9690 - 578ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "188/188 - 1s - loss: 0.1074 - accuracy: 0.9679 - val_loss: 0.1151 - val_accuracy: 0.9683 - 536ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "188/188 - 1s - loss: 0.1108 - accuracy: 0.9668 - val_loss: 0.1136 - val_accuracy: 0.9680 - 544ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "188/188 - 1s - loss: 0.1163 - accuracy: 0.9636 - val_loss: 0.1136 - val_accuracy: 0.9683 - 639ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "188/188 - 1s - loss: 0.1120 - accuracy: 0.9642 - val_loss: 0.1222 - val_accuracy: 0.9667 - 600ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "188/188 - 1s - loss: 0.1080 - accuracy: 0.9672 - val_loss: 0.1133 - val_accuracy: 0.9673 - 608ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "188/188 - 1s - loss: 0.1115 - accuracy: 0.9657 - val_loss: 0.1114 - val_accuracy: 0.9677 - 585ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "188/188 - 1s - loss: 0.1073 - accuracy: 0.9665 - val_loss: 0.1136 - val_accuracy: 0.9677 - 544ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "188/188 - 1s - loss: 0.1050 - accuracy: 0.9682 - val_loss: 0.1257 - val_accuracy: 0.9643 - 537ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "188/188 - 1s - loss: 0.1121 - accuracy: 0.9665 - val_loss: 0.1154 - val_accuracy: 0.9677 - 576ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "188/188 - 1s - loss: 0.1068 - accuracy: 0.9676 - val_loss: 0.1180 - val_accuracy: 0.9680 - 566ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "188/188 - 1s - loss: 0.1046 - accuracy: 0.9680 - val_loss: 0.1115 - val_accuracy: 0.9673 - 567ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "188/188 - 1s - loss: 0.1243 - accuracy: 0.9592 - val_loss: 0.1115 - val_accuracy: 0.9680 - 597ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "188/188 - 1s - loss: 0.1072 - accuracy: 0.9682 - val_loss: 0.1075 - val_accuracy: 0.9687 - 572ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "188/188 - 1s - loss: 0.1048 - accuracy: 0.9678 - val_loss: 0.1112 - val_accuracy: 0.9677 - 532ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "188/188 - 1s - loss: 0.1060 - accuracy: 0.9671 - val_loss: 0.1129 - val_accuracy: 0.9670 - 523ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "188/188 - 1s - loss: 0.1062 - accuracy: 0.9683 - val_loss: 0.1101 - val_accuracy: 0.9687 - 522ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "188/188 - 1s - loss: 0.1048 - accuracy: 0.9686 - val_loss: 0.1125 - val_accuracy: 0.9690 - 507ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "188/188 - 1s - loss: 0.1043 - accuracy: 0.9676 - val_loss: 0.1118 - val_accuracy: 0.9663 - 552ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "188/188 - 1s - loss: 0.1009 - accuracy: 0.9684 - val_loss: 0.1161 - val_accuracy: 0.9680 - 523ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "188/188 - 1s - loss: 0.1025 - accuracy: 0.9687 - val_loss: 0.1096 - val_accuracy: 0.9687 - 533ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "188/188 - 1s - loss: 0.1033 - accuracy: 0.9690 - val_loss: 0.1150 - val_accuracy: 0.9683 - 550ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "188/188 - 1s - loss: 0.1049 - accuracy: 0.9692 - val_loss: 0.1083 - val_accuracy: 0.9667 - 517ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "188/188 - 1s - loss: 0.1096 - accuracy: 0.9662 - val_loss: 0.1130 - val_accuracy: 0.9670 - 516ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "188/188 - 1s - loss: 0.1061 - accuracy: 0.9656 - val_loss: 0.1156 - val_accuracy: 0.9667 - 514ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "188/188 - 1s - loss: 0.1072 - accuracy: 0.9669 - val_loss: 0.1125 - val_accuracy: 0.9690 - 528ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "188/188 - 1s - loss: 0.1034 - accuracy: 0.9690 - val_loss: 0.1176 - val_accuracy: 0.9653 - 515ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "188/188 - 1s - loss: 0.0983 - accuracy: 0.9693 - val_loss: 0.1119 - val_accuracy: 0.9693 - 511ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "188/188 - 1s - loss: 0.0988 - accuracy: 0.9692 - val_loss: 0.1232 - val_accuracy: 0.9677 - 539ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "188/188 - 1s - loss: 0.1016 - accuracy: 0.9669 - val_loss: 0.1160 - val_accuracy: 0.9673 - 561ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "188/188 - 1s - loss: 0.1012 - accuracy: 0.9676 - val_loss: 0.1094 - val_accuracy: 0.9677 - 542ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "188/188 - 1s - loss: 0.0978 - accuracy: 0.9699 - val_loss: 0.1137 - val_accuracy: 0.9683 - 526ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "188/188 - 1s - loss: 0.0955 - accuracy: 0.9705 - val_loss: 0.1057 - val_accuracy: 0.9697 - 520ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "188/188 - 1s - loss: 0.0985 - accuracy: 0.9707 - val_loss: 0.1085 - val_accuracy: 0.9687 - 532ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "188/188 - 1s - loss: 0.1022 - accuracy: 0.9696 - val_loss: 0.1115 - val_accuracy: 0.9677 - 536ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "188/188 - 1s - loss: 0.0947 - accuracy: 0.9700 - val_loss: 0.1068 - val_accuracy: 0.9680 - 518ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "188/188 - 1s - loss: 0.1020 - accuracy: 0.9687 - val_loss: 0.1066 - val_accuracy: 0.9700 - 521ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "188/188 - 1s - loss: 0.1008 - accuracy: 0.9690 - val_loss: 0.1050 - val_accuracy: 0.9687 - 536ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "188/188 - 1s - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.1059 - val_accuracy: 0.9690 - 514ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "188/188 - 1s - loss: 0.0952 - accuracy: 0.9707 - val_loss: 0.1167 - val_accuracy: 0.9680 - 529ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "188/188 - 1s - loss: 0.1019 - accuracy: 0.9664 - val_loss: 0.1117 - val_accuracy: 0.9697 - 546ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "188/188 - 1s - loss: 0.0971 - accuracy: 0.9694 - val_loss: 0.1170 - val_accuracy: 0.9683 - 531ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "188/188 - 1s - loss: 0.0980 - accuracy: 0.9697 - val_loss: 0.1041 - val_accuracy: 0.9680 - 528ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "188/188 - 1s - loss: 0.0924 - accuracy: 0.9711 - val_loss: 0.1107 - val_accuracy: 0.9693 - 511ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "188/188 - 1s - loss: 0.0933 - accuracy: 0.9707 - val_loss: 0.1142 - val_accuracy: 0.9687 - 526ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "188/188 - 1s - loss: 0.0955 - accuracy: 0.9706 - val_loss: 0.1138 - val_accuracy: 0.9683 - 524ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "188/188 - 1s - loss: 0.0901 - accuracy: 0.9722 - val_loss: 0.1066 - val_accuracy: 0.9703 - 572ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "188/188 - 1s - loss: 0.0977 - accuracy: 0.9697 - val_loss: 0.1115 - val_accuracy: 0.9687 - 565ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "188/188 - 1s - loss: 0.0985 - accuracy: 0.9691 - val_loss: 0.1159 - val_accuracy: 0.9667 - 559ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "188/188 - 1s - loss: 0.0929 - accuracy: 0.9713 - val_loss: 0.1084 - val_accuracy: 0.9700 - 559ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd35a58970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=100,verbose=2,validation_data=[X_test,y_test],batch_size=64,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2250,   44],\n",
       "       [  77,  629]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred>0.5,1,0)\n",
    "tf.math.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966910</td>\n",
       "      <td>0.980820</td>\n",
       "      <td>0.973815</td>\n",
       "      <td>2294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.934621</td>\n",
       "      <td>0.890935</td>\n",
       "      <td>0.912255</td>\n",
       "      <td>706.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.959667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.950766</td>\n",
       "      <td>0.935877</td>\n",
       "      <td>0.943035</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.959328</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.966910  0.980820  0.973815  2294.000000\n",
       "1              0.934621  0.890935  0.912255   706.000000\n",
       "accuracy       0.959667  0.959667  0.959667     0.959667\n",
       "macro avg      0.950766  0.935877  0.943035  3000.000000\n",
       "weighted avg   0.959311  0.959667  0.959328  3000.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9678fcbbceb5ef7bd2be700e1ce0e75cd9a08123793b1fd2775eecef6b74d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
