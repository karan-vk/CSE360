{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom PIL import Image\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\nfrom tqdm import tqdm\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-01T17:07:07.820335Z","iopub.execute_input":"2022-03-01T17:07:07.820807Z","iopub.status.idle":"2022-03-01T17:07:07.826947Z","shell.execute_reply.started":"2022-03-01T17:07:07.820769Z","shell.execute_reply":"2022-03-01T17:07:07.826068Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_images = glob(\"../input/whale-categorization-playground/train/*jpg\")\ntest_images = glob(\"../input/whale-categorization-playground/test/*jpg\")\ndf = pd.read_csv(\"../input/whale-categorization-playground/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:08:17.067073Z","iopub.execute_input":"2022-03-01T17:08:17.067629Z","iopub.status.idle":"2022-03-01T17:08:17.162588Z","shell.execute_reply.started":"2022-03-01T17:08:17.067593Z","shell.execute_reply":"2022-03-01T17:08:17.161911Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df[\"Image\"] = df[\"Image\"].map( lambda x : \"train/\"+x)\nImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:08:30.427479Z","iopub.execute_input":"2022-03-01T17:08:30.427741Z","iopub.status.idle":"2022-03-01T17:08:30.438958Z","shell.execute_reply.started":"2022-03-01T17:08:30.427710Z","shell.execute_reply":"2022-03-01T17:08:30.438297Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"SIZE = 100\n#image are imported and resized\ndef ImportImage( filename):\n    img = Image.open(filename).resize( (SIZE,SIZE))\n    img = np.array(img)\n    if img.ndim == 2: #imported BW picture and converting to \"dumb RGB\"\n        img = np.tile( img, (3,1,1)).transpose((1,2,0))\n    return img\nx_train = np.array([ImportImage( img) for img in train_images],dtype=np.uint8)\n\n\n\nprint( \"%d training images\" %x_train.shape[0])\n\nprint( \"Nbr of samples/class\\tNbr of classes\")\nfor index, val in df[\"Id\"].value_counts().value_counts().sort_index().iteritems():\n    print( \"%d\\t\\t\\t%d\" %(index,val))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:08:32.990385Z","iopub.execute_input":"2022-03-01T17:08:32.990831Z","iopub.status.idle":"2022-03-01T17:10:45.524579Z","shell.execute_reply.started":"2022-03-01T17:08:32.990793Z","shell.execute_reply":"2022-03-01T17:10:45.523836Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class LabelOneHotEncoder():\n    def __init__(self):\n        self.ohe = OneHotEncoder()\n        self.le = LabelEncoder()\n    def fit_transform(self, x):\n        features = self.le.fit_transform( x)\n        return self.ohe.fit_transform( features.reshape(-1,1))\n    def transform( self, x):\n        return self.ohe.transform( self.la.transform( x.reshape(-1,1)))\n    def inverse_tranform( self, x):\n        return self.le.inverse_transform( self.ohe.inverse_tranform( x))\n    def inverse_labels( self, x):\n        return self.le.inverse_transform( x)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:11:29.787885Z","iopub.execute_input":"2022-03-01T17:11:29.788259Z","iopub.status.idle":"2022-03-01T17:11:29.794583Z","shell.execute_reply.started":"2022-03-01T17:11:29.788221Z","shell.execute_reply":"2022-03-01T17:11:29.793879Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y = list(map(ImageToLabelDict.get, train_images))\nlohe = LabelOneHotEncoder()\ny_cat = lohe.fit_transform(y)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:11:37.421728Z","iopub.execute_input":"2022-03-01T17:11:37.421989Z","iopub.status.idle":"2022-03-01T17:11:37.434346Z","shell.execute_reply.started":"2022-03-01T17:11:37.421957Z","shell.execute_reply":"2022-03-01T17:11:37.433648Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n#use of an image generator for preprocessing and data augmentation\nx_train = x_train.reshape( (-1,SIZE,SIZE,3))\ninput_shape = x_train[0].shape\n#x_train = x_train.astype(\"float32\")\ny_train = y_cat\n\nimage_gen = ImageDataGenerator(\n    #featurewise_center=True,\n    #featurewise_std_normalization=True,\n\trescale=1./255,\n    rotation_range=15,\n    width_shift_range=.15,\n    height_shift_range=.15,\n    horizontal_flip=True)\n\n#training the image preprocessing\nimage_gen.fit(x_train, augment=True)\n\n#visualization of some images out of the preprocessing\n#augmented_images, _ = next( image_gen.flow( x_train, y_train.toarray(), batch_size=4*4))\n#plotImages( augmented_images)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:12:00.388880Z","iopub.execute_input":"2022-03-01T17:12:00.389569Z","iopub.status.idle":"2022-03-01T17:12:21.846248Z","shell.execute_reply.started":"2022-03-01T17:12:00.389530Z","shell.execute_reply":"2022-03-01T17:12:21.845333Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nnum_classes = len(y_cat.toarray()[0])\nepochs = 10 #x_train.shape[0]//batch_size + 1\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\n\nmodel = Sequential()\n\n#picking vgg16 as pretrained (base) model https://keras.io/applications/#vgg16\nconv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nfor layer in conv_base.layers:\n    layer.trainable = False\n\n#maybe unfreeze last layer\nconv_base.layers[-2].trainable = True\n\nmodel.add( conv_base)\nmodel.add(Flatten())\nmodel.add(Dropout(0.33))\nmodel.add(Dense(48, activation='relu')) #64\nmodel.add(Dropout(0.33))\nmodel.add(Dense(48, activation='relu')) #48\nmodel.add(Dropout(0.33))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=\"adam\",\n              metrics=['accuracy'])\nmodel.summary()\nmodel.fit_generator(image_gen.flow(x_train, y_train.toarray(), batch_size=batch_size),\n          steps_per_epoch=x_train.shape[0] // epochs,\n          epochs=epochs,\n         verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:14:22.129936Z","iopub.execute_input":"2022-03-01T17:14:22.130316Z","iopub.status.idle":"2022-03-01T17:15:04.591500Z","shell.execute_reply.started":"2022-03-01T17:14:22.130281Z","shell.execute_reply":"2022-03-01T17:15:04.590669Z"},"trusted":true},"execution_count":20,"outputs":[]}]}